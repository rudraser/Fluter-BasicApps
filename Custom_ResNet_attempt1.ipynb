{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8AimeqelKiCjSV0j9R+H7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudraser/Fluter-BasicApps/blob/main/Custom_ResNet_attempt1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOcx0lBgghLm"
      },
      "source": [
        "import torch\n",
        "import torchvision # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouBDlC9Jgoqm"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "data_path = '/data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(size=[32,32], padding=4),                        \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i03NlEVDgyMa"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '/data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(size=[32,32], padding=4),                        \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PIfI9Cg4VD"
      },
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(self, in_channels)\n",
        "        super(block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self,x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return x + out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0fEJYKvlHms"
      },
      "source": [
        "class ResNet(nn.Module)\n",
        "    def __init__(self, in=48, n_blocks=8):\n",
        "        super().__init__()\n",
        "        self.in = in\n",
        "        self.conv1 = nn.Conv2d(3, in, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in, 2*in, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(2*in, 4*in, kernel_size=3, padding=1)       # defing layers for forward\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [resblock(n=in)]))\n",
        "        self.resblocks2 = nn.Sequential(\n",
        "            *((n_blocks*3) * [resblock(n=in*2)]))\n",
        "        self.resblocks3 = nn.Sequential(\n",
        "            *(n_blocks * [resblock(n=in*4)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * in*4, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 10)\n",
        "\n",
        "    def forward(self, x):                    # using the resblocks 3 times, each with twice the number of channels as before\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.resblocks(x)                          \n",
        "        x = F.max_pool2d(x, 2) \n",
        "        x = self.conv2(x)\n",
        "        x = self.resblocks2(x)\n",
        "        x = F.max_pool2d(x, 2) \n",
        "        x = self.conv3(x)\n",
        "        x = self.resblocks3(x)\n",
        "        x = x.view(-1, 8 * 8 * self.in*4)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVBuJngWmhMe"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):           # defining the training loop\n",
        "    for epoch in range(1, n_epochs + 1):                                        # these inputs would be defined in next cell\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        \n",
        "        print('{} Epoch {}, Training loss {}'.format(\n",
        "            datetime.datetime.now(), epoch,\n",
        "            loss_train / len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8S3Yvirmh-U"
      },
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=32,\n",
        "                                           shuffle=True)                   \n",
        "\n",
        "model =  deep().to(device=device)# <1>\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0AfUtEimwEm"
      },
      "source": [
        "training_loop(                   #calling the training loop finally\n",
        "    n_epochs = 60,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmJwXzbFm21b"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():   # we do no need backpropagation for this hence the nograd\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # taking the class at maximum probability as prediction\n",
        "                total += labels.shape[0]  \n",
        "                correct += int((predicted == labels).sum())   # calculating the no. of correct predictions.\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}