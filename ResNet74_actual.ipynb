{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet74_actual.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDHb6zartQ8yGl7SPdXxGa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29054f3833804e79af4bcaea56ba8623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_90baf892d9cc48b4ab919bb2999e418e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_424fcd18986c4479b57adce6f1163e9a",
              "IPY_MODEL_102f4d9eb1b746e8b762e389d2d3274e"
            ]
          }
        },
        "90baf892d9cc48b4ab919bb2999e418e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "424fcd18986c4479b57adce6f1163e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4925eb09b66d417c815e31483df0f7a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb456421153e4eccb4f35277483e8691"
          }
        },
        "102f4d9eb1b746e8b762e389d2d3274e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83e8581570be4564ae14c6b374531ce0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:04&lt;00:00, 41734801.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82dc2430555348189d6cb3577530cb5c"
          }
        },
        "4925eb09b66d417c815e31483df0f7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb456421153e4eccb4f35277483e8691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83e8581570be4564ae14c6b374531ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82dc2430555348189d6cb3577530cb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudraser/Fluter-BasicApps/blob/main/ResNet74_actual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ABe7Aq2VNQ",
        "outputId": "8520743e-80ab-43f3-f3fb-855bcaf5d573"
      },
      "source": [
        "import torch\n",
        "import torchvision # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kv-NX62gfC"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "29054f3833804e79af4bcaea56ba8623",
            "90baf892d9cc48b4ab919bb2999e418e",
            "424fcd18986c4479b57adce6f1163e9a",
            "102f4d9eb1b746e8b762e389d2d3274e",
            "4925eb09b66d417c815e31483df0f7a5",
            "fb456421153e4eccb4f35277483e8691",
            "83e8581570be4564ae14c6b374531ce0",
            "82dc2430555348189d6cb3577530cb5c"
          ]
        },
        "id": "j6huR3Ll2kdS",
        "outputId": "e2f5a372-0746-4874-df61-fec46316eebf"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '/data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(size=[32,32], padding=4),                        \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data-unversioned/p1ch6/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29054f3833804e79af4bcaea56ba8623",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /data-unversioned/p1ch6/cifar-10-python.tar.gz to /data-unversioned/p1ch6/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1inimGz2mUg",
        "outputId": "fe6bd5be-0618-46ff-a931-35e9acdf2eed"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VBq_L3N2ovw"
      },
      "source": [
        "class resblock(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels,identity_downsample=None, stride=1):\n",
        "        super(resblock, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv2 = nn.Conv2d(mid_channels,mid_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv3 = nn.Conv2d(mid_channels,mid_channels * self.expansion,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(mid_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYM3qApj5GmS"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, resblock, layers, image_channels = 3, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        \n",
        "        self.layer1 = self._create_layer(resblock, layers[0], mid_channels=64, stride=1)\n",
        "        self.layer2 = self._create_layer(resblock, layers[1], mid_channels=128, stride=2)\n",
        "        self.layer3 = self._create_layer(resblock, layers[2], mid_channels=256, stride=2)\n",
        "        self.layer4 = self._create_layer(resblock, layers[3], mid_channels=512, stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(512 * 4, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _create_layer(self, resblock, num_residual_blocks, mid_channels, stride):\n",
        "        identity_downsample = None\n",
        "        new_layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != mid_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    mid_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(mid_channels * 4),\n",
        "            )\n",
        "\n",
        "        new_layers.append(\n",
        "            resblock(self.in_channels, mid_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = mid_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            new_layers.append(resblock(self.in_channels, mid_channels))\n",
        "\n",
        "        return nn.Sequential(*new_layers)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M21G-7ZsZqKn"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        \n",
        "        print('{} Epoch {}, Training loss {}'.format(\n",
        "            datetime.datetime.now(), epoch,\n",
        "            loss_train / len(train_loader)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvo7IO0qZrNL"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "model =  ResNet(resblock,[3, 6, 12, 3]).to(device=device)# <1>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCq8KO5FZyTq",
        "outputId": "9372c5c7-4b8f-46a2-e2d5-033fb888b004"
      },
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30837530,\n",
              " [9408,\n",
              "  64,\n",
              "  64,\n",
              "  4096,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  32768,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  131072,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  131072,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  524288,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  524288,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  2097152,\n",
              "  2048,\n",
              "  2048,\n",
              "  1048576,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  1048576,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  65536,\n",
              "  32,\n",
              "  512,\n",
              "  16,\n",
              "  160,\n",
              "  10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwUpiGSHaNkM",
        "outputId": "f938ccd9-9b9a-4c4a-f89b-288326148d1c"
      },
      "source": [
        "training_loop(  \n",
        "    n_epochs = 35,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-30 13:20:00.937812 Epoch 1, Training loss 1.8669263214406455\n",
            "2021-07-30 13:21:04.451455 Epoch 2, Training loss 1.5535072237634293\n",
            "2021-07-30 13:22:07.980964 Epoch 3, Training loss 1.408302397679185\n",
            "2021-07-30 13:23:11.579371 Epoch 4, Training loss 1.2936536613327767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2heWoTXaW3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "af612db5-faf8-4bd5-efe3-ce07ec15a7ba"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-438be1f33d11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                            shuffle=False)\n\u001b[1;32m      3\u001b[0m val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n\u001b[1;32m      4\u001b[0m                                          shuffle=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    }
  ]
}